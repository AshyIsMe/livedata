---
phase: 01-process-monitoring-core
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/process_monitor.rs
  - src/lib.rs
  - src/web_server.rs
autonomous: true

must_haves:
  truths:
    - "Process data is collected in background at fixed intervals"
    - "API endpoint returns current process snapshot with PID, name, CPU%, memory%, user, runtime"
    - "Process collection refreshes System state correctly for accurate CPU metrics"
  artifacts:
    - path: "src/process_monitor.rs"
      provides: "ProcessMonitor struct with background collection task"
      min_lines: 80
      exports: ["ProcessMonitor", "ProcessInfo"]
    - path: "src/web_server.rs"
      provides: "GET /api/processes endpoint"
      contains: "api_processes"
  key_links:
    - from: "src/process_monitor.rs"
      to: "sysinfo::System"
      via: "refresh_processes and refresh_cpu_usage calls"
      pattern: "refresh_processes.*ProcessesToUpdate::All"
    - from: "src/web_server.rs"
      to: "ProcessMonitor"
      via: "AppState field and handler access"
      pattern: "process_monitor\\.get_snapshot"
---

<objective>
Implement backend process collection using sysinfo crate and expose process data via API endpoint.

Purpose: Establish foundation for process monitoring - collect system process data in background and make it available to web interface.
Output: ProcessMonitor module collecting process snapshots, API endpoint serving current snapshot as JSON.
</objective>

<execution_context>
@/home/agentsmith/.config/opencode/get-shit-done/workflows/execute-plan.md
@/home/agentsmith/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-process-monitoring-core/01-CONTEXT.md
@.planning/phases/01-process-monitoring-core/01-RESEARCH.md
@src/lib.rs
@src/web_server.rs
@src/app_controller.rs
@Cargo.toml
</context>

<tasks>

<task type="auto">
  <name>Create ProcessMonitor module with sysinfo integration</name>
  <files>src/process_monitor.rs, src/lib.rs, Cargo.toml</files>
  <action>
Add sysinfo and fuzzy-matcher dependencies:
```bash
cargo add sysinfo@0.38
cargo add fuzzy-matcher@0.3.7
```

Create src/process_monitor.rs following the pattern from 01-RESEARCH.md "Complete ProcessMonitor Module":

1. Define ProcessInfo struct with serde derives:
   - Fields: pid (u32), name (String), cpu_percent (f32), memory_bytes (u64), user_id (Option<String>), runtime_secs (u64)
   - Derive: Debug, Clone, Serialize, Deserialize

2. Create ProcessMonitor struct:
   - Fields: system (Arc<Mutex<System>>), snapshot (Arc<Mutex<Vec<ProcessInfo>>>)
   - Implement new() that initializes System with new_all() and refresh_all()

3. Implement start_collection(interval_secs: u64) method:
   - Clone Arc references for tokio task
   - Spawn tokio task with interval timer
   - In loop: refresh_processes with ProcessesToUpdate::All and ProcessRefreshKind::everything()
   - Call refresh_cpu_usage() for accurate CPU metrics
   - Map system.processes() to Vec<ProcessInfo>, storing in snapshot mutex
   - Use name().to_string_lossy().to_string() for process name (handles non-UTF8)
   - Use format!("{:?}", user_id) for user_id display

4. Implement get_snapshot() -> Vec<ProcessInfo>:
   - Clone and return current snapshot from mutex

5. Add module to src/lib.rs:
   - Add `pub mod process_monitor;` line

Use imports:
- sysinfo::{System, ProcessRefreshKind, ProcessesToUpdate}
- serde::{Deserialize, Serialize}
- std::sync::{Arc, Mutex}
- tokio::time::{interval, Duration}

DO NOT use MINIMUM_CPU_UPDATE_INTERVAL sleep - not needed with periodic refresh pattern. DO NOT store processes in DuckDB yet (phase 1 is in-memory only).
  </action>
  <verify>
cargo build succeeds without errors
cargo clippy shows no warnings for process_monitor.rs
  </verify>
  <done>
- src/process_monitor.rs exists with ProcessMonitor and ProcessInfo implementations
- Module compiles successfully
- ProcessMonitor::new() initializes System
- start_collection() spawns background task
- get_snapshot() returns Vec<ProcessInfo>
  </done>
</task>

<task type="auto">
  <name>Add /api/processes endpoint to web server</name>
  <files>src/web_server.rs</files>
  <action>
Extend src/web_server.rs following existing pattern (api_logs endpoint):

1. Add ProcessMonitor to AppState struct:
   - Add field: process_monitor: Arc<ProcessMonitor>
   - Import: use crate::process_monitor::{ProcessMonitor, ProcessInfo};
   - Import: use std::sync::Arc;

2. Update run_web_server signature to accept process_monitor parameter:
   - Change signature: pub async fn run_web_server(data_dir: &str, shutdown_signal: Arc<AtomicBool>, process_monitor: Arc<ProcessMonitor>)
   - Pass process_monitor into AppState initialization

3. Create ProcessResponse struct (with serde derives):
   - Fields: processes (Vec<ProcessInfo>), timestamp (String), total (usize)
   - Derive: Serialize

4. Create api_processes handler following api_logs pattern:
   - Signature: async fn api_processes(State(state): State<Arc<AppState>>) -> Result<Json<ProcessResponse>, (StatusCode, String)>
   - Get snapshot: state.process_monitor.get_snapshot()
   - Build response with processes, current timestamp (chrono::Utc::now().to_rfc3339()), total count
   - Return Json(ProcessResponse {...})

5. Add route to router:
   - In run_web_server, add .route("/api/processes", get(api_processes)) to api_routes

Imports needed:
- axum::{extract::State, http::StatusCode, Json, routing::get}
- chrono (already in Cargo.toml)

Follow existing error handling pattern from api_logs (StatusCode, String) tuple for errors.
  </action>
  <verify>
cargo build succeeds
cargo clippy shows no warnings
Signature of run_web_server includes process_monitor parameter
  </verify>
  <done>
- AppState has process_monitor field
- api_processes handler exists and returns ProcessResponse JSON
- Route /api/processes registered in router
- Handler follows existing API patterns (State extraction, error handling)
  </done>
</task>

</tasks>

<verification>
Build and lint checks:
```bash
cargo build --release
cargo clippy --all-targets -- -D warnings
cargo fmt --check
```

Module integration:
- ProcessMonitor is pub exported from lib.rs
- web_server.rs compiles with new process_monitor parameter
- API endpoint structure matches existing api_logs pattern
</verification>

<success_criteria>
- cargo build succeeds without errors or warnings
- ProcessMonitor module exists with background collection capability
- /api/processes endpoint defined and integrated into web server router
- Code follows existing patterns (Arc<Mutex> for shared state, tokio spawn for background tasks)
- Imports are organized and minimal
</success_criteria>

<output>
After completion, create `.planning/phases/01-process-monitoring-core/01-01-SUMMARY.md`
</output>
